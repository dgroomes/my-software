# strategy

My software strategy. Think things like tech radar, tech stack synergy, etc.


## Overview

This is a **work in progress**. I need a space to collect and organize ideas and note that make up my so-called "software strategy". This strategy doc has a stream-of-consciousness tinge to it. That's fine. In a way, it's just meant to be a launching pad, scratchpad or temporary scaffold to produce something more enduring, which is my collection of software subprojects.

In 2026, agentic AI is the 600 pound gorilla that needs to be included in the strategy. One of my focus areas is sandboxing. I get so much value from agentic coding collaborators like Claude Code, Codex, GitHub Copilot, and there's so much more value to squeeze out of them if only I could let them work for longer task horizons and without oversight.

I've explored sandboxing items like macOS seatbelt. I've thought a lot about running it in a Docker container or running it in a VM. What I want to do is keep fleshing out these an understanding of these tools and working them, trying them out in my own workflow. For various reasons, there's no clear winner because of the fast accumulation of complexity when you adopt these tools. This is a high cost. Consider on macOS, you can't even run containers, you have to run them by way of a virtual machine, Docker Desktop, Colima, all these things have layers to them that require constant updates, filling up a mental model, compatibility, etc.

Seatbelt itself is deprecated. I really don't have a strong sense of what the right tool is, I just need to get going. I explored running macOS VMs using Tart in 2025, but I barely scratched the surface. Recently, I did Docker in Docker and found it to be just really quite layered in incidental complexity, cryptic shell stuff in the DinD scripts, etc. I think if I was using Linux as my main machine, I would of course just use containers.

I also don't want to use some SaaS for remote dev boxes because that creates an enormously larger footprint. A high cost. I think I want to try some more macOS VMs.

I think the guiding light here is that macOS, like any OS, is a valid, viable computing platform. It is a viable and effective **development** platform. I don't need to toss that away. I have to pick one of the OSes, and macOS is my choice. Layering in Linux is fine, but it represents literally a doubling of OS in my dev flow. I already invest and understand and have a desire to enrich my understanding of macOS. And so, I think it's viable to explore running my agentic workloads or "dev boxes" in a macOS VM on my Mac. I think Tart is the way to go. I've been curious to just use the Apple virtualization APIs directly and writing my own CLI utility in Swift, but for now, Tart is perfectly fine. A special call out to [Lima](https://github.com/lima-vm/lima), but that's strictly focused on Linux VMs on macOS. So let's use Tart for now.

One thing I don't like about the idea of macOS on macOS is that sometimes the boundaries, from a cold start, is confusing. It's similar to server-side JavaScript or these days, React server components, where if you're waking up and the first thing you see is a tweet, blog post, or uncommitted file in your Git project, and it's TypeScript, you don't automatically know if that runs client-side or server-side. And within the same file, you don't even know what lines are running client-side or server-side (e.g. `use server` and the linke). I think isomorphic TypeScript (or anything) is super neat, but it comes with this murky boundary. "Java everywhere" was a fun idea, never happened. Still fun to think about embedded Java. It's a tradeoff. Same thing with self-bootstrapping programming languages. It's like, what are we doing? Of course you need to bootstrap from A to B. How does it make sense to bootstrap from B to B, e.g., Java compiling Java; TypeScript compiling TypeScript, etc. So I'm not sure about that type of inception. And similarly, I have a desire to learn more Linux. I'm not trying to demote it for my own forecast. But I think it might just be practical to limit it. So it's very much a secondary OS, something where I It's a runtime target for workloads, things like that. It's not a first-class development environment for me. Let's keep macOS as that. macOS is desktop only software. Appl even gave up on server-side macOS. Let that be the end of that. I'm going to try out macOS "dev box" VMs running on my macbook using Tart. It is a directional goal to eject from Tart and code straight to the Virtualization framework APIs via a custom Swift CLI. As a corollary, it is not a directional goal to lean into macOS VM image-building tech like Packer, or into more layers of indirection between my dev flow and the dev box. 


## Consolidating Control

There is a force within software components and processes and systems where a given component wants control. It is the "make me master" story. This is a classic story. We see this frequently with so-called *build* tools. The build tools started as a way to compile our programs, to preprocess them, to zip them up. The build tools became *run* tools. Gradle wants to run your tests. It wants to run your application (via the Gradle `run` command and a shell *start* script it creates). Spring's machinery builds this tower even higher. Spring Boot's Gradle plugin creates a `bootRun` command. Spring wants to run your program. NPM wants to run your scripts. NPM wants to define scripts as shell snippets inside a JSON file (`package.json`). NPX wants to run your NPM commands. Git wants to house aliased commands. So many processes desire root. These things all make sense. As they are built and designed from their own vantage point, but our vantage point is our own center of gravity. Our center of control will be the *main* methods and entrypoint functions that we define. Our center of control will be our shell (Nushell). Our center of control will be our host OS (macOS). And in the world of agents, our center of control is the agent process. The "make me master" story is one I've seen and recognized over the years. When we recognize it, we can be better equipped to say no, to keep our control. It's less about consolidating control and more about preventing the dilution of the control we already have.

So, this guiding principle introduces concepts like the Go-based launcher program I have for Java (JVM) programs. I have a desire to create a similar launcher programs for JavaScript (Node.js/Bun) programs. I have a desire to run a coding agent, e.g. Claude Code or Codex, from my host Mac and have it send commands and change files in a remote dev box. I don't need the agent process to run inside the remote dev box. That creates problems like putting the authentication tokens inside the remote dev box. When we consider where the control power shifts, it can make more clear the boundaries, the useful interfaces between components. It's tempting to just give up control, but it often creates more problems than it solves, and it certainly dilutes our understanding and control and comprehension of the system that we're interacting with. "Build time versus runtime" is a similar or related example of this control where we push left the work, the verification. Maybe the biggest tangible way that this control story appears is in the number of dependencies we have in a project. As dependencies grow, we lose control over our over the absolute execution paths of our program at runtime, increase the surface area of supply chain attacks, we give up during comprehension. Of course, we require and desire to use dependencies, but it is quality over quantity. It is surely the case that quality beats quantity in a software dependency strategy. We retain control over selecting these dependencies, ejecting from them, upgrading between versions on our own schedule.

One of the "table stakes" assumptions I've made about my own dev workflow is a dependency on Docker. I simply assume that I need it in an absolute sense because so many projects express a useful set of local dev flows using very neat docker-compose.yml files. And of course, these projects build the Docker image to run the production. This tech stack comes at enormous cost on macOS. We bring in Docker Desktop or Colima and Lima. We create a VM inside which we have containers. Docker itself isn't even necessary for containers, and yet we conflate Docker with cgroups. The control we had, we gladly gave to this Docker-based workflow. Now with smart LLMs, we want to get the extreme leverage that they deliver, and to get to those green pastures, we may have to eject from, "assumed essential" technologies like Docker. The agent demands control. The agent expects the ability to burrow around a file system, expects the ability to run shell commands. It's best if we can grant it that ability so that we can see the results as it executes over a long horizon, without interventions. We still want to limit its ability to interact outside of the sandbox, but even then, it can be useful to allow it a vast registry of dependencies to choose from to complete its task, feature, or bug fix. That's what matters more than other development conveniences pre-LLMs. We see this difference with the IDE. In theory, a rich, graphical, polished, fast, intuitive user experience over our code and processes (an IDE) is clearly higher bandwidth than the equivalent monospaced experience in a terminal, but the fact is, command line coding agents have iterated far faster and effectively than GUI-based coding agents. This is truly the KISS principle (Keep It Stupid Simple). Finding that last mile of UX is a later thing. Finding a groove in agent-based development is the main thing, and that's why we use these command-line based agents. And they've been successful. I love IntelliJ, but agentic dev on IntelliJ is not there yet, and that's okay. I'll go where it works. I use IntelliJ for the diff, nav, and edits. Intellij is not allowed to own the agentic loop.
